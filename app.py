# æ‰‹é †4-4: ãƒ¡ã‚¤ãƒ³ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ç’°å¢ƒå¤‰æ•°ã®èª­ã¿è¾¼ã¿
from dotenv import load_dotenv
load_dotenv()

import streamlit as st
from langchain_openai import ChatOpenAI
from langchain.prompts import SystemMessagePromptTemplate, HumanMessagePromptTemplate, ChatPromptTemplate
from langchain.schema import AIMessage, HumanMessage

# --- å°‚é–€å®¶ã®å®šç¾© ---
EXPERT_A_NAME = "æ­´å²å­¦è€…"
EXPERT_A_ROLE = "ã‚ãªãŸã¯ä¸–ç•Œä¸­ã®æ­´å²ã«ç²¾é€šã—ãŸæ­´å²å­¦è€…ã§ã™ã€‚è³ªå•ã«å¯¾ã—ã¦ã€æ­£ç¢ºã§è©³ç´°ãªæ­´å²çš„èƒŒæ™¯ã‚„äº‹å®Ÿã«åŸºã¥ã„ã¦å›ç­”ã—ã¦ãã ã•ã„ã€‚æƒ…å ±ã®å‡ºæ‰€ã‚„æ™‚ä»£èƒŒæ™¯ã‚‚ç¤ºã—ã€å°‚é–€å®¶ã¨ã—ã¦ã®æ·±ã¿ã®ã‚ã‚‹è§£èª¬ã‚’å¿ƒãŒã‘ã¦ãã ã•ã„ã€‚"

EXPERT_B_NAME = "ãƒ•ã‚¡ã‚¤ãƒŠãƒ³ã‚·ãƒ£ãƒ«ãƒ—ãƒ©ãƒ³ãƒŠãƒ¼"
EXPERT_B_ROLE = "ã‚ãªãŸã¯å€‹äººã®è³‡ç”£é‹ç”¨ã‚„ç¨åˆ¶ã«è©³ã—ã„ãƒ•ã‚¡ã‚¤ãƒŠãƒ³ã‚·ãƒ£ãƒ«ãƒ—ãƒ©ãƒ³ãƒŠãƒ¼ã§ã™ã€‚è³ªå•è€…ã®çŠ¶æ³ã«åŸºã¥ãã€å®Ÿç¾å¯èƒ½ã§ãƒªã‚¹ã‚¯ã‚’è€ƒæ…®ã—ãŸå…·ä½“çš„ãªè³‡ç”£å½¢æˆã®ã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚’ã—ã¦ãã ã•ã„ã€‚å°‚é–€ç”¨èªã¯åˆ†ã‹ã‚Šã‚„ã™ãèª¬æ˜ã—ã€ä¿¡é ¼ã§ãã‚‹æƒ…å ±æºã«åŸºã¥ã„ãŸå›ç­”ã‚’ã—ã¦ãã ã•ã„ã€‚"


# --- å‡¦ç†ã‚’æ‹…ã†é–¢æ•° ---
def get_llm_response(input_text: str, selected_expert: str) -> str:
    """
    LLMã‹ã‚‰ã®å›ç­”ã‚’å–å¾—ã™ã‚‹é–¢æ•°

    Args:
        input_text (str): ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‹ã‚‰ã®å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆ
        selected_expert (str): ãƒ©ã‚¸ã‚ªãƒœã‚¿ãƒ³ã§é¸æŠã•ã‚ŒãŸå°‚é–€å®¶ã®åå‰

    Returns:
        str: LLMã‹ã‚‰ã®å›ç­”
    """
    # é¸æŠã«å¿œã˜ã¦ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’æ±ºå®š
    if selected_expert == EXPERT_A_NAME:
        system_role = EXPERT_A_ROLE
    elif selected_expert == EXPERT_B_NAME:
        system_role = EXPERT_B_ROLE
    else:
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®š (ã‚ã‚Šãˆãªã„ãŒå¿µã®ãŸã‚)
        system_role = "ã‚ãªãŸã¯è¦ªåˆ‡ãªAIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚"

    # LangChainã®ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆæ§‹ç¯‰
    system_message_prompt = SystemMessagePromptTemplate.from_template(system_role)
    human_message_prompt = HumanMessagePromptTemplate.from_template("{text}")
    
    chat_prompt = ChatPromptTemplate.from_messages([
        system_message_prompt, 
        human_message_prompt
    ])
    
    # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
    formatted_prompt = chat_prompt.format_messages(text=input_text)

    # LLMã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹åŒ– (Pythonã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã¯3.11ã‚’æƒ³å®š)
    # LangChainã®OpenAIãƒ¢ãƒ‡ãƒ«ã¯ã€è‡ªå‹•ã§ç’°å¢ƒå¤‰æ•° OPENAI_API_KEY ã‚’å‚ç…§ã—ã¾ã™ã€‚
    # model_nameã«ã¯ã”è‡ªèº«ã®OpenAIã‚¢ã‚«ã‚¦ãƒ³ãƒˆã§åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ã‚’æŒ‡å®šã—ã¦ãã ã•ã„ã€‚
    llm = ChatOpenAI(temperature=0.7, model_name="gpt-3.5-turbo") 

    # LLMã®å‘¼ã³å‡ºã—
    response = llm.invoke(formatted_prompt)

    # å›ç­”ãƒ†ã‚­ã‚¹ãƒˆã‚’è¿”ã™
    return response.content


# --- Streamlit UIæ§‹ç¯‰ ---

# Webã‚¢ãƒ—ãƒªã®æ¦‚è¦ã‚„æ“ä½œæ–¹æ³•ã‚’ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«æ˜ç¤º
st.title("ğŸ‘¨â€ğŸ« å°‚é–€å®¶é¸æŠå¼ LLM ã‚¢ãƒ—ãƒª")
st.write("ã“ã®ã‚¢ãƒ—ãƒªã§ã¯ã€ãƒ©ã‚¸ã‚ªãƒœã‚¿ãƒ³ã§é¸æŠã—ãŸå°‚é–€å®¶ã®ãƒ­ãƒ¼ãƒ«ã«åŸºã¥ãã€LLMãŒå›ç­”ã‚’è¡Œã„ã¾ã™ã€‚")
st.markdown("---")


# ãƒ©ã‚¸ã‚ªãƒœã‚¿ãƒ³ã§å°‚é–€å®¶ã‚’é¸æŠ
selected_expert = st.sidebar.radio(
    "1. å°‚é–€å®¶ã‚’é¸æŠã—ã¦ãã ã•ã„",
    (EXPERT_A_NAME, EXPERT_B_NAME)
)
st.sidebar.markdown(f"**é¸æŠä¸­ã®å°‚é–€å®¶**: **{selected_expert}**")
st.sidebar.markdown("---")

# ãƒ¡ã‚¤ãƒ³ç”»é¢ã«å…¥åŠ›ãƒ•ã‚©ãƒ¼ãƒ ã‚’é…ç½®
user_input = st.text_area(
    "2. è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„:",
    placeholder=f"ä¾‹: {selected_expert}ã«è³ªå•ã—ãŸã„å†…å®¹ã‚’ã“ã“ã«å…¥åŠ›..."
)

# é€ä¿¡ãƒœã‚¿ãƒ³
if st.button("è³ªå•ã‚’é€ä¿¡"):
    if user_input:
        st.info("å›ç­”ã‚’ç”Ÿæˆä¸­ã§ã™...ã—ã°ã‚‰ããŠå¾…ã¡ãã ã•ã„ã€‚")
        
        # é–¢æ•°ã‚’å‘¼ã³å‡ºã—LLMã®å›ç­”ã‚’å–å¾—
        try:
            llm_response = get_llm_response(user_input, selected_expert)
            
            # çµæœã®è¡¨ç¤º
            st.success(f"ğŸ¤– **{selected_expert}** ã‹ã‚‰ã®å›ç­”:")
            st.markdown(llm_response)
        
        except Exception as e:
            st.error(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            st.warning("OpenAI APIã‚­ãƒ¼ãŒæ­£ã—ãè¨­å®šã•ã‚Œã¦ã„ã‚‹ã‹ã€ã¾ãŸã¯èª²é‡‘ãŒæœ‰åŠ¹ã«ãªã£ã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
            
    else:
        st.warning("è³ªå•ã‚’å…¥åŠ›ã—ã¦ã‹ã‚‰é€ä¿¡ãƒœã‚¿ãƒ³ã‚’æŠ¼ã—ã¦ãã ã•ã„ã€‚")

# ã‚¢ãƒ—ãƒªå®Ÿè¡Œæ–¹æ³•: ä»®æƒ³ç’°å¢ƒã‚’æœ‰åŠ¹ã«ã—ãŸçŠ¶æ…‹ã§ `streamlit run app.py` ã‚’ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³ã§å®Ÿè¡Œã—ã¾ã™ã€‚